{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "#standard\n",
    "from collections import Counter, defaultdict, namedtuple\n",
    "import re\n",
    "\n",
    "# extra\n",
    "from funcy import memoize\n",
    "import pandas as pd\n",
    "\n",
    "# local\n",
    "from data_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in dirty data\n",
    "train = pd.read_json('data/train.json', orient='records', encoding='utf-8')\n",
    "test = pd.read_json('data/test.json', orient='records', encoding='utf-8')\n",
    "\n",
    "# set indices and join train and test data\n",
    "train.set_index('id', drop=True, inplace=True)\n",
    "test.set_index('id', drop=True, inplace=True)\n",
    "test.insert(0, 'cuisine', 'test')\n",
    "data = pd.concat((train, test), axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ing = namedtuple('Ing', ['string', 'head', 'mods', 'states', 'brands', 'langs', 'cuisine', 'rcpid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform dirty string into Ing\n",
    "@memoize\n",
    "def make_ing(orig_phrase):\n",
    "    # WARNING: these are done in this order for reasons\n",
    "    \n",
    "    phrase = orig_phrase.lower()\n",
    "\n",
    "    # standardize 'n' and '&' to 'and'\n",
    "    phrase = phrase.replace('&', ' and ')\n",
    "    phrase = phrase.replace(' n ', ' and ')\n",
    "    \n",
    "    # strip extra whitespace\n",
    "    phrase = ' '.join(phrase.split())\n",
    "    \n",
    "    # correct special spelling words\n",
    "    # WARNING: strip extra whitespace first\n",
    "    for k, v in compiled_spelling:\n",
    "        phrase = k.sub(v, phrase)    \n",
    "    \n",
    "    # handle exceptions\n",
    "    # WARNING: correct special spelling first\n",
    "    for k, v in compiled_exceptions:\n",
    "        phrase = k.sub(v, phrase)\n",
    "\n",
    "    # remove parentheticals\n",
    "    phrase = parenthetical_pattern.sub('', phrase)\n",
    "\n",
    "    # remove useless chars\n",
    "    # WARNING: remove parentheticals before removing individual '()' chars\n",
    "    phrase = phrase.replace('â€', '')\n",
    "    phrase = char_pattern.sub('', phrase)\n",
    "\n",
    "    # sub and move brands\n",
    "    brands = []\n",
    "    match = compiled_brands.search(phrase)\n",
    "    if match:\n",
    "        brand = match.group(0)\n",
    "        sub = brands_to_sub[brand] if brand in brands_to_sub else ''\n",
    "        phrase = phrase.replace(brand, sub)\n",
    "        brand = '_brand-{}'.format(brand.replace(' ', '')[:4])\n",
    "        brands = brands + [brand] # avoid mutations when memoized\n",
    "    \n",
    "    # remove chars kept for brand recognition\n",
    "    # WARNING: handle brands first\n",
    "    phrase = brand_char_pattern.sub('', phrase)\n",
    "    \n",
    "    # remove trailing prep instructions\n",
    "    phrases = phrase.split(',')\n",
    "    phrase = phrases[0]\n",
    "    phrases = phrase.split(' for ')\n",
    "    phrase = phrases[0]\n",
    "    \n",
    "    # move either 'with x' or 'in x' phrases to front\n",
    "    # WARNING: handle exceptions first\n",
    "    phrases = phrase.split(' with ')\n",
    "    if len(phrases) > 1:\n",
    "        phrase = ' '.join([phrases[1], phrases[0]])\n",
    "    else:\n",
    "        phrases = phrase.split(' in ')\n",
    "        if len(phrases) > 1:\n",
    "            phrase = ' '.join([phrases[1], phrases[0]])\n",
    "    \n",
    "    # sub ' of (the)? ' with 'of'\n",
    "    phrase = of_pattern.sub(r'\\1of', phrase)\n",
    "    # merge modwords\n",
    "    phrase = low_pattern.sub(' low', phrase)\n",
    "    phrase = free_pattern.sub('free ', phrase)\n",
    "    phrase = high_pattern.sub(' high', phrase)\n",
    "    \n",
    "    # make ing\n",
    "    words = [word for word in phrase.split() if word not in stopwords]\n",
    "    words = [correct_spelling(word) if len(word) > 4 else word for word in words]\n",
    "    phrases = [words_to_segment[word].split() if word in words_to_segment else [word] for word in words]\n",
    "    words = [get_lemma(word) for words in phrases for word in words] # get lemma and flatten\n",
    "    words = remove_first_dupes(words)\n",
    "    langs = ['_lang-{}'.format(lang_trans[word]) for word in words if word in lang_trans]\n",
    "    states = ['_state-{}'.format(word[:5]) for word in words if word in state_words]\n",
    "    words = [word for word in words if word not in state_words]\n",
    "    for _ in range(len(words)):\n",
    "        head = words[-1]\n",
    "        if head in heads_to_drop:\n",
    "            words = words[:-1] # avoid mutations when memoized\n",
    "            if not words and head in heads_to_sub:\n",
    "                words = [heads_to_sub[head]]\n",
    "        else:\n",
    "            break\n",
    "    if not words:\n",
    "        print(orig_phrase)\n",
    "        return ([], [], [], [], [], [])\n",
    "    if words[-1] in supertype_appends:\n",
    "        words = words + [supertype_appends[words[-1]]] # avoid mutations when memoized\n",
    "    words = remove_first_dupes(words)\n",
    "    head = words[-1]\n",
    "    mod_words = sorted(words[:-1])\n",
    "    string = ' '.join(mod_words + [head])\n",
    "    if not mod_words:\n",
    "        mods = [head]\n",
    "    else:\n",
    "        mods = ['{}-{}'.format(head, mod) for mod in mod_words]\n",
    "    return (string, head, mods, states, brands, langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ings(recipe):\n",
    "    ings = []\n",
    "    for phrase in recipe.ingredients:\n",
    "        string, head, mods, states, brands, langs = make_ing(phrase)\n",
    "        if not head:\n",
    "            continue\n",
    "        ing = Ing(string, head, mods, states, brands, langs, recipe.cuisine, recipe.name)\n",
    "        ings.append(ing)\n",
    "    return ings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear caches\n",
    "make_ing.memory.clear()\n",
    "get_lemma.memory.clear()\n",
    "\n",
    "ings_series = data.apply(make_ings, axis='columns')\n",
    "len(ings_series) # 49718"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_ings = ings_series.map(flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = ings_series.map(lambda ings: [ing.string for ing in ings])\n",
    "strings.name = 'strings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "data.ingredients = flattened_ings\n",
    "data = pd.concat([data, strings], axis='columns')\n",
    "data.to_csv('data/cleaned_data.csv', header=True, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

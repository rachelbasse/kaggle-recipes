{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "#standard\n",
    "from collections import Counter, defaultdict, namedtuple\n",
    "from itertools import chain\n",
    "import re\n",
    "\n",
    "# extra\n",
    "from funcy import memoize\n",
    "import pandas as pd\n",
    "\n",
    "# local\n",
    "from data_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in dirty data\n",
    "train = pd.read_json('data/train.json', orient='records', encoding='utf-8')\n",
    "test = pd.read_json('data/test.json', orient='records', encoding='utf-8')\n",
    "\n",
    "# set indices and join train and test\n",
    "train.set_index('id', drop=True, inplace=True)\n",
    "test.set_index('id', drop=True, inplace=True)\n",
    "test.insert(0, 'cuisine', 'test')\n",
    "data = pd.concat((train, test), axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@memoize\n",
    "def clean_phrase(orig_phrase):\n",
    "    phrase = orig_phrase.lower()\n",
    "    \n",
    "    # remove useless chars\n",
    "    phrase = char_pattern.sub('', phrase)\n",
    "    \n",
    "    # standardize 'n' and '&' to 'and'; '-' to ' '\n",
    "    phrase = phrase.replace('&', ' and ')\n",
    "    phrase = phrase.replace(' n ', ' and ')\n",
    "    phrase = phrase.replace('-', ' ')\n",
    "    \n",
    "    # remove prep instructions\n",
    "    split = phrase.split(',')\n",
    "    phrase = split[0]\n",
    "    split = phrase.split(' for ')\n",
    "    phrase = split[0]\n",
    "    \n",
    "    # move 'with x', 'in x' phrases to front\n",
    "    split = phrase.split(' with ')\n",
    "    if len(split) > 1:\n",
    "        # CR is this reverse?\n",
    "        phrase = ' '.join([split[1], split[0]])\n",
    "    split = phrase.split(' in ')\n",
    "    if len(split) > 1:\n",
    "        phrase = ' '.join([split[1], split[0]])\n",
    "\n",
    "    # strip extra whitespace\n",
    "    phrase = ' '.join(phrase.split())\n",
    "    \n",
    "    # hacky spelling correction\n",
    "    for k, v in spellcheck_compiled:\n",
    "        phrase = k.sub(v, phrase)\n",
    "    \n",
    "    # hacky pepper substitution\n",
    "    if phrase.strip() == 'pepper':\n",
    "        return 'bpepper'\n",
    "    \n",
    "    # substitute phrases\n",
    "    split = phrase.split()\n",
    "    # CR why is this not string.replace?\n",
    "    for i, word in enumerate(split):\n",
    "        if word in words_to_sub:\n",
    "            split[i] = words_to_sub[word]\n",
    "    phrase = ' '.join(split)\n",
    "    for k, v in phrases_to_sub.items():\n",
    "        sub = ' ' + v + ' '\n",
    "        phrase = sub.join(phrase.split(k))\n",
    "    \n",
    "    # sub ' of (the)? ' with 'of'\n",
    "    phrase = of_pattern.sub(r'\\1of', phrase)\n",
    "    \n",
    "    # strip extra whitespace\n",
    "    phrase = ' '.join(phrase.split())\n",
    "\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_words(phrases):\n",
    "    res = set()\n",
    "    for phrase in phrases:\n",
    "        if not phrase:\n",
    "            continue\n",
    "        split = phrase.split()\n",
    "        for i, word in enumerate(split):\n",
    "            if len(word.split('-')) > 1:\n",
    "                res.add(word)\n",
    "                split[i] = 'below' # stopword\n",
    "                continue\n",
    "            if len(word) > 4:\n",
    "                split[i] = correct_spelling(word)\n",
    "            if word in words_to_segment:\n",
    "                    split[i] = segment_word(word)\n",
    "        split = remove_first_dupes(split)\n",
    "        split = lemmatize(' '.join(split))\n",
    "        if not split:\n",
    "            continue\n",
    "        for word in split:\n",
    "            if word in lang_trans:\n",
    "                res.add('{}-l'.format(lang_trans[word]))\n",
    "        if len(split) > 1:\n",
    "            res.add('-'.join(split[-2:]))\n",
    "        res.update(split)\n",
    "    return list(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear caches\n",
    "clean_phrase.memory.clear()\n",
    "lemmatize.memory.clear()\n",
    "\n",
    "# clean data\n",
    "cleaned_phrases = data.ingredients.map(lambda phrases: [clean_phrase(phrase) for phrase in phrases])\n",
    "print('phrases cleaned')\n",
    "#cleaned_words = cleaned_phrases.map(clean_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.ingredients = cleaned_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ing = namedtuple('Ing', ['words', 'langs', 'cuisine', 'rcpid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ings(recipe):\n",
    "    ings = []\n",
    "    for phrase in recipe.ingredients:\n",
    "        if not phrase:\n",
    "            continue\n",
    "        words = phrase.split()\n",
    "        for i, word in enumerate(words):\n",
    "            if len(word) > 4:\n",
    "                words[i] = correct_spelling(word)\n",
    "            if word in words_to_segment:\n",
    "                    words[i] = segment_word(word)\n",
    "        words = remove_first_dupes(words)\n",
    "        words = lemmatize(' '.join(words))\n",
    "        words = words[::-1]\n",
    "        if not words:\n",
    "            continue\n",
    "        langs = []\n",
    "        for word in words:\n",
    "            if word in lang_trans:\n",
    "                langs.append('lang{}'.format(lang_trans[word]))\n",
    "        ing = Ing(words, langs, recipe.cuisine, recipe.name)    \n",
    "        ings.append(ing)\n",
    "    return ings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ings_df = data.apply(make_ings, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ings = [ing for ings in ings_df for ing in ings]\n",
    "len(ings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by head:\n",
    "heads = defaultdict(list)\n",
    "for ing in iter(ings):\n",
    "    heads[ing.words[0]].append(ing)\n",
    "len(heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_info = {}\n",
    "for head, ings_list in heads.items():\n",
    "    words, cuisines = set(), set()\n",
    "    for ing in iter(ings_list):\n",
    "        words.add(tuple(ing.words))\n",
    "        cuisines.add(ing.cuisine)\n",
    "    head_info[head] = [words, cuisines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_counts = defaultdict(list)\n",
    "for head, info in head_info.items():\n",
    "    phrase_count = len(info[0])\n",
    "    head_counts[phrase_count].append(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = sorted([(phrase_count, len(heads)) for phrase_count, heads in head_counts.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "todo = []\n",
    "for var, count in iter(counts):\n",
    "    if var > 50:\n",
    "        todo.append(head_counts[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist(words):\n",
    "    counts = Counter([ing.cuisine for ing in iter(ings) if ing.words == words and ing.cuisine != 'test'])\n",
    "    total = sum(counts.values())\n",
    "    for k, v in counts.items():\n",
    "        counts[k] = round(100 * v / total)\n",
    "    return (total, sorted(counts.items(), key=itemgetter(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dist(['sauce', 'hot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dist(['sauce', 'hot', 'cholula'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ing for ing in iter(ings) if len(ing.words) > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[47431].ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatize('italian dressing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_info['dressing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "data.ingredients = cleaned_words\n",
    "data.to_csv('data/cleaned_data.csv', header=True, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

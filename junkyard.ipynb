{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "# extra\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# local\n",
    "from feature_helpers import *\n",
    "\n",
    "# display settings\n",
    "sns.set(style='whitegrid', palette='husl')\n",
    "pd.set_option('display.max_colwidth', 400)\n",
    "pd.set_option('display.precision', 4)\n",
    "pd.set_option('display.width', 1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes = load_clean_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = get_metrics(recipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.sort_values('unique_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid', palette='husl')\n",
    "recipe_counts_plot = sns.catplot(x='recipe_count', y='cuisine', data=metrics, kind='bar', height=7, aspect=1.8,\n",
    "                                 order=metrics.recipe_count.sort_values(ascending=False).index)\n",
    "recipe_counts_plot.set(xticks=range(0, 10500, 500));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_lengths_plot = sns.catplot(x='recipe_length', y='cuisine', data=metrics, kind='bar', height=7, aspect=1.5,\n",
    "                                  order=metrics.recipe_length.sort_values(ascending=False).index)\n",
    "recipe_lengths_plot.set(xticks=range(0, 15, 2));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_counts_plot = sns.catplot(x='head_count', y='cuisine', data=metrics, kind='bar', height=7, aspect=1.5,\n",
    "                              order=metrics.head_count.sort_values(ascending=False).index)\n",
    "head_counts_plot.set(xticks=range(0, 122000, 20000));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "sns.set_color_codes('pastel')\n",
    "unique_counts_plot = sns.barplot(x='unique_count', y='cuisine', data=metrics, label='unique ings', color='b', ax=ax,\n",
    "                              order=metrics.unique_count.sort_values(ascending=False).index)\n",
    "rare_counts_plot = sns.barplot(x='rare_count', y='cuisine', data=metrics, label='rare ings', color='r', ax=ax,\n",
    "                              order=metrics.unique_count.sort_values(ascending=False).index)\n",
    "ax.legend(ncol=2, loc='lower right', frameon=True)\n",
    "unique_counts_plot.set(xticks=range(0, 1100, 100));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for friendlier plotting\n",
    "def reshape_tfidfs(tfidfs):\n",
    "    pairs = []\n",
    "    for cuisine, vals in tfidfs.iterrows():\n",
    "        pairs.extend([[cuisine, v] for v in vals if v > 0.0001])\n",
    "    return pd.DataFrame(pairs, columns=['cuisine', 'tfidf'])\n",
    "tfidfs = make_tfidfs(recipes.query('cuisine != \"test\"'))\n",
    "smoothed_tfidfs = smooth_tfidfs(tfidfs, .6)\n",
    "reshaped_tfidfs = reshape_tfidfs(tfidfs)\n",
    "reshaped_smoothed_tfidfs = reshape_tfidfs(smoothed_tfidfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "all_tfidfs_plot = sns.distplot(reshaped_tfidfs.tfidf, kde=False)\n",
    "all_tfidfs_plot.set(xticks=np.arange(0, .46, .02));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "max_tfidf = reshaped_smoothed_tfidfs.tfidf.max()\n",
    "all_smoothed_tfidfs_plot = sns.distplot(reshaped_smoothed_tfidfs.tfidf, kde=False)\n",
    "all_smoothed_tfidfs_plot.set(xticks=np.arange(0, max_tfidf + .05, .1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_tfidfs_plot = sns.catplot(y='tfidf', x='cuisine', data=reshaped_tfidfs, kind='strip', height=7, aspect=2.5,\n",
    "                             order=metrics.unique_count.sort_values(ascending=False).index)\n",
    "cuisine_tfidfs_plot.set(yticks=np.arange(0, .45, .05));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tfidf = reshaped_smoothed_tfidfs.tfidf.max()\n",
    "smoothed_cuisine_tfidfs_plot = sns.catplot(y='tfidf', x='cuisine', data=reshaped_smoothed_tfidfs, kind='strip', height=7, aspect=2.5,\n",
    "                             order=metrics.unique_count.sort_values(ascending=False).index)\n",
    "smoothed_cuisine_tfidfs_plot.set(yticks=np.arange(0, max_tfidf + .1, .05));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dist(dist):\n",
    "    dist_min = dist.min()\n",
    "    dist_range = dist.max() - dist_min\n",
    "    normed = dist.map(lambda x: (x - dist_min) / dist_range)\n",
    "    return normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_indicators(recipes, features, renamed):\n",
    "    indicators = np.zeros([recipes.shape[0], len(features)], dtype=np.uint8)\n",
    "    feature_index = {feature: i for i, feature in enumerate(features)}\n",
    "    for row_i, ings in enumerate(recipes.ingredients):\n",
    "        recipe_features = [renamed[feature] if feature in renamed else feature for feature in ings]\n",
    "        for feature in recipe_features:\n",
    "            indicators[row_i, feature_index[feature]] = 1\n",
    "    indicators = pd.DataFrame(indicators, index=recipes.index, columns=features)\n",
    "    return pd.concat([recipes.cuisine, indicators], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importances(train):\n",
    "    X = train.drop(columns=['cuisine'])\n",
    "    y = train['cuisine']\n",
    "    rfc = RandomForestClassifier(min_samples_leaf=8, random_state=1, class_weight='balanced', n_estimators=200, criterion='gini')\n",
    "    rfc_grid = {\n",
    "        'max_depth': [20, 24],\n",
    "        'min_samples_split': [15, 25, 35]\n",
    "    }\n",
    "    search = RandomizedSearchCV(rfc, param_distributions=rfc_grid, refit=True, n_iter=5, cv=3, n_jobs=-1)\n",
    "    search.fit(X, y)\n",
    "    best = search.best_estimator_\n",
    "    print('Best score: {0:.3f}, train score: {1:.3f}'.format(search.best_score_, best.score(X, y)))\n",
    "    print(search.best_params_)\n",
    "    return pd.Series(best.feature_importances_, index=X.columns)\n",
    "\n",
    "def merge_unused_features(recipes, counts, renamed, catchall):\n",
    "    indicators = make_indicators(recipes, counts.index.to_list(), renamed)\n",
    "    importances = get_feature_importances(indicators)\n",
    "    \n",
    "    unused_features = importances[importances == 0].index.to_list()\n",
    "    long_features = [feature for feature in unused_features if len(feature.split('-')) > 1]\n",
    "    merged, renamed_update = merge_features(counts, long_features, catchall)\n",
    "    renamed = merge_arrows(renamed, renamed_update)\n",
    "    \n",
    "    indicators = make_indicators(recipes, merged.index.to_list(), renamed)\n",
    "    importances = get_feature_importances(indicators)\n",
    "    \n",
    "    unused_features = importances[importances == 0].index.to_list()\n",
    "    merged, renamed_update = merge_features(merged, unused_features, catchall)\n",
    "    renamed = merge_arrows(renamed, renamed_update)\n",
    "    \n",
    "    return (merged, renamed)\n",
    "\n",
    "unused_merged, renamed_update = merge_unused_features(recipes, rare_merged, renamed, 'raretype')\n",
    "renamed = merge_arrows(renamed, renamed_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize_counts(counts, smooth_type='linear', smooth_intensity=.7):\n",
    "    smoothing_funcs = {\n",
    "        'linear': lambda x: smooth_intensity * x,\n",
    "        'tanh': lambda x: tanh(x),\n",
    "        'sqrt_sigmoid': lambda x: x / sqrt(1 + x**2),\n",
    "        'frac_sigmoid': lambda x: x / (smooth_intensity + x)\n",
    "    }\n",
    "    total = counts.sum(axis='columns')\n",
    "    inverse_total = total.map(lambda x: 1 / x if x else 0)\n",
    "    proportions = counts.T * inverse_total\n",
    "    if smooth_type:\n",
    "        proportions = proportions.applymap(smoothing_funcs[smooth_type])\n",
    "    return proportions.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_split(data, val_size, seed):\n",
    "    samples = []\n",
    "    for cuisine, group in data.groupby('cuisine'):\n",
    "        jiggle = np.random.choice([0, .01, .02, .03])\n",
    "        samples.append(group.sample(frac=val_size + jiggle, replace=False, random_state=seed, axis='index'))\n",
    "    val = pd.concat(samples, axis='index')\n",
    "    train = data.drop(index=val.index)\n",
    "    X_train = train.drop(columns=['cuisine'])\n",
    "    X_val = val.drop(columns=['cuisine'])\n",
    "    y_train = train['cuisine']\n",
    "    y_val = val['cuisine']\n",
    "    return (X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_hyperparams(data, clf, grid, metric, val_size, splits=3):\n",
    "    param_grid = ParameterGrid(grid)\n",
    "    scores = defaultdict(list)\n",
    "    for i in range(splits):\n",
    "        X_train, y_train, X_val, y_val = train_validate_split(data, val_size, seed=i)\n",
    "        best_model, best_score, _, _ = pf.bestFit(\n",
    "            clf, param_grid, X_train, y_train, X_val, y_val, metric=metric, greater_is_better=True)\n",
    "        scores[best_score].append(best_model)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct = lambda v: int(v * 100)\n",
    "\n",
    "def test(X, y, title, clf, sampler=None, splits=3):\n",
    "    kfold = KFold(n_splits=splits, shuffle=True, random_state=1)\n",
    "    for train_i, test_i in kfold.split(X):\n",
    "        X_train, X_test = X.iloc[train_i], X.iloc[test_i]\n",
    "        y_train, y_test = y.iloc[train_i], y.iloc[test_i]\n",
    "        if sampler:\n",
    "            X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "        model = clf.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        print(metrics.accuracy_score(y_test, preds))\n",
    "        print(metrics.classification_report(y_test, preds))\n",
    "\n",
    "def get_errors(X, y, model, sort_col=None):\n",
    "    errors = []\n",
    "    preds = []\n",
    "    for i in range(X.shape[0]):\n",
    "        obs = X.iloc[i:i+1]\n",
    "        real = y.iloc[i]\n",
    "        y_pred = model.predict(obs)\n",
    "        if y_pred != [real]:\n",
    "            errors.append(i)\n",
    "            preds.append(y_pred)\n",
    "    errs = pd.concat([X.iloc[errors], y.iloc[errors]], axis=1)\n",
    "    preds_df = pd.DataFrame(preds, index=errs.index, columns=['pred'])\n",
    "    errs = pd.concat([errs, preds_df], axis=1)\n",
    "    print('Errors:', errs.shape[0])\n",
    "    if sort_col:\n",
    "        errs.sort_values(sort_col, inplace=True)\n",
    "    return errs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

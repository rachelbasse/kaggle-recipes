{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "# standard\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import combinations, product\n",
    "from math import log\n",
    "\n",
    "#extra\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clean_data():\n",
    "    recipes = pd.read_csv('data/cleaned_data.csv', header=0, index_col=0, encoding='utf-8',\n",
    "                          # convert list literals to lists\n",
    "                          converters={'ingredients': lambda x: eval(x), 'strings': lambda x: eval(x)})\n",
    "    print('{:,} recipes'.format(recipes.shape[0]))\n",
    "    return recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda lists: [item for lst in lists for item in lst]\n",
    "inverse = lambda x: 1 / x if x else 0\n",
    "rank = lambda score: score * inverse(score.max())\n",
    "ratio = lambda score: score * inverse(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dupes(ings):\n",
    "    return ings.map(set).map(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_combos(ings):\n",
    "    combos = lambda lst: lst + list(map('+'.join, combinations(sorted(lst), 2)))\n",
    "    return ings.map(combos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_names(ings, renamed):\n",
    "    return [renamed[feature] if feature in renamed else feature for feature in ings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_counts(recipes, field='ingredients'):\n",
    "    counts = {}\n",
    "    for cuisine, group in recipes.groupby('cuisine'):\n",
    "        all_ings = flatten(group[field].to_list())\n",
    "        counts[cuisine] = Counter(all_ings)\n",
    "    counts = pd.DataFrame.from_dict(counts, orient='columns', dtype=np.float64)\n",
    "    counts.fillna(0.0, inplace=True)\n",
    "    counts.test = 0.0\n",
    "    print('{} features'.format(counts.shape[0]))\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scale(series):\n",
    "    series_min = series.min()\n",
    "    scaled = series - series_min\n",
    "    series_max = scaled.max()\n",
    "    return series / series_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_counts(counts, scales):\n",
    "    counts = counts.apply(lambda col: col.map(lambda x: x / scales[col.name]), axis='index')\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_arrows(arrows, update):\n",
    "    arrows.update(update)\n",
    "    for origin, target in arrows.items():\n",
    "        if target in arrows:\n",
    "            arrows[origin] = arrows[target]\n",
    "    return arrows\n",
    "\n",
    "def get_target_feature(feature, bad_features, catchall):\n",
    "    parts = feature.split('-')\n",
    "    if parts[-1] == catchall:\n",
    "        target = parts[0]\n",
    "    else:\n",
    "        parts[-1] = catchall\n",
    "        target = '-'.join(parts)\n",
    "    if target in bad_features:\n",
    "        target = get_target_feature(target, bad_features, catchall)\n",
    "    return target\n",
    "\n",
    "def merge_features(counts, features_to_merge, catchall):\n",
    "    renamed_features = {}\n",
    "    counts = counts.copy()\n",
    "    if catchall in features_to_merge:\n",
    "        features_to_merge = features_to_merge.copy()\n",
    "        features_to_merge.remove(catchall)\n",
    "    features_to_keep = set(counts.index) - set(features_to_merge)\n",
    "    for feature in features_to_merge:\n",
    "        target = get_target_feature(feature, features_to_merge, catchall)\n",
    "        renamed_features[feature] = target\n",
    "        if target in features_to_keep:\n",
    "            counts.loc[target] += counts.loc[feature]\n",
    "            continue\n",
    "        counts.loc[target] = counts.loc[feature]\n",
    "    counts = counts.drop(index=features_to_merge)\n",
    "    print('{} merged, {} features left'.format(len(renamed_features), len(counts)))\n",
    "    return (counts, renamed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_rare_features(counts, single_cutoff, combo_cutoff, catchall):\n",
    "    totals = counts.max(axis='columns')\n",
    "    rare_combo_features = totals[totals <= combo_cutoff].index.to_list()\n",
    "    combo_features = [feature for feature in rare_combo_features if '+' in feature]\n",
    "    merged = counts.drop(index=combo_features)\n",
    "    print('{} combo features dropped'.format(len(combo_features)))\n",
    "    renamed = {old: 'rarecombotype' for old in combo_features}\n",
    "\n",
    "    totals = merged.max(axis='columns')\n",
    "    rare_features = totals[totals <= single_cutoff].index.to_list()\n",
    "    long_features = [feature for feature in rare_features if len(feature.split('-')) > 1]\n",
    "    merged, renamed_update = merge_features(merged, long_features, catchall)\n",
    "    renamed = merge_arrows(renamed, renamed_update)\n",
    "    \n",
    "    totals = merged.max(axis='columns')\n",
    "    rare_features = totals[totals <= single_cutoff].index.to_list()\n",
    "    raretype_features = [feature for feature in rare_features if len(feature.split('-')) > 1]\n",
    "    merged, renamed_update = merge_features(merged, raretype_features, catchall)\n",
    "    renamed = merge_arrows(renamed, renamed_update)\n",
    "    \n",
    "    totals = merged.max(axis='columns')\n",
    "    rare_features = totals[totals <= single_cutoff].index.to_list()\n",
    "    merged, renamed_update = merge_features(merged, rare_features, catchall)\n",
    "    renamed = merge_arrows(renamed, renamed_update)\n",
    "    \n",
    "    return (merged, renamed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proportions(counts):\n",
    "    total = counts.sum(axis='columns')\n",
    "    inverse_total = total.map(lambda x: 1 / x if x else 0)\n",
    "    proportions = counts.T * inverse_total\n",
    "    return proportions.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_indicators(recipes, features):\n",
    "    indicators = np.zeros([recipes.shape[0], len(features)], dtype=np.uint8)\n",
    "    feature_index = {feature: i for i, feature in enumerate(features)}\n",
    "    for row_i, ings in enumerate(recipes.ingredients):\n",
    "        for feature in ings:\n",
    "            indicators[row_i, feature_index[feature]] = 1\n",
    "    indicators = pd.DataFrame(indicators, index=recipes.index, columns=features)\n",
    "    return indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reweight(data, weights):\n",
    "    smooth = lambda data, w: data.map(lambda x: w[0] * log(1.01 + (x / (w[1] + x))) if x else 0)\n",
    "    adjusted = data.copy()\n",
    "    for col, weight in weights.items():\n",
    "        adjusted[col] = smooth(adjusted[col], weight)\n",
    "    return adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_scores(recipe, points):\n",
    "    scores = points.loc[recipe.ingredients]\n",
    "    sums = scores.sum(axis='columns')\n",
    "    mean_sum = sums.mean()\n",
    "    groups = scores.groupby(lambda name: sums[name] > mean_sum, axis='index', sort=False).mean()\n",
    "    low = groups.loc[False].add_prefix('low_')\n",
    "    return pd.concat([scores.mean(), low], axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ings_only(data):\n",
    "    adjusted = data.copy()\n",
    "    to_zero = [feature for feature in adjusted.index if '_brand' in feature or '_lang' in feature]\n",
    "    adjusted.loc[to_zero] = 0\n",
    "    return adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {\n",
    "    'east': ['chinese', 'filipino', 'indian', 'japanese', 'korean', 'thai', 'vietnamese'],\n",
    "    'west': ['russian', 'british', 'irish', 'french', 'italian', 'greek', 'spanish', 'cajun_creole',\n",
    "             'moroccan', 'southern_us', 'mexican', 'jamaican', 'brazilian'],\n",
    "    'chineselike': ['chinese', 'filipino', 'japanese', 'korean', 'thai', 'vietnamese'],\n",
    "    'indianlike': ['indian', 'japanese', 'mexican', 'moroccan', 'southern_us', 'thai'],\n",
    "    'britishlike': ['british', 'french', 'irish'],\n",
    "    'italianlike': ['greek', 'italian', 'mexican', 'spanish'],\n",
    "    'southern_uslike': ['brazilian', 'british', 'cajun_creole', 'irish', 'jamaican', 'southern_us']\n",
    "}\n",
    "def make_group_features(scores, groups=groups):\n",
    "    to_add = []\n",
    "    for name, group in groups.items():\n",
    "        series = scores[group].mean(axis='columns')\n",
    "        series.name = name\n",
    "        to_add.append(series)\n",
    "    return pd.concat(to_add, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisons = [\n",
    "    ('british', 'french'),\n",
    "    ('british', 'irish'),\n",
    "    ('french', 'italian'),\n",
    "    ('greek', 'italian'),\n",
    "    ('greek', 'moroccan'),\n",
    "    ('indian', 'japanese'),\n",
    "    ('italian', 'spanish'),\n",
    "    ('thai', 'vietnamese'),\n",
    "    \n",
    "    ('brazilian', 'southern_us'),\n",
    "    ('british', 'southern_us'),\n",
    "    ('cajun_creole', 'southern_us'),\n",
    "    ('french', 'southern_us'),\n",
    "    ('greek', 'southern_us'),\n",
    "    ('irish', 'southern_us'),\n",
    "    ('italian', 'southern_us'),\n",
    "    ('jamaican', 'southern_us'),\n",
    "    ('moroccan', 'southern_us'),\n",
    "    ('mexican', 'southern_us'),\n",
    "    ('russian', 'southern_us'),\n",
    "    ('spanish', 'southern_us'),\n",
    "    \n",
    "    ('filipino', 'chinese'),\n",
    "    ('indian', 'chinese'),\n",
    "    ('japanese', 'chinese'),\n",
    "    ('korean', 'chinese'),\n",
    "    ('thai', 'chinese'),\n",
    "    ('vietnamese', 'chinese'),\n",
    "]\n",
    "def make_comparison_features(scores, comparisons=comparisons):\n",
    "    to_add = []\n",
    "    for a, b in comparisons:\n",
    "        series = scores[a] * scores[b].map(inverse)\n",
    "        series.name = '-'.join([a, b])\n",
    "        to_add.append(series)\n",
    "    return pd.concat(to_add, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cnf(conf_matrix, classes):\n",
    "    f, ax = plt.subplots(figsize=(9,9))\n",
    "    sns.heatmap(conf_matrix, square=True, annot=True, fmt='d', cbar=False, cmap='Blues',\n",
    "                xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel('predicted label')\n",
    "    plt.ylabel('true label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_output(output, prefix='temp_'):\n",
    "    output = output.drop(columns=['ingredients', 'strings'])\n",
    "    \n",
    "    train = output.query('cuisine != \"test\"')\n",
    "    test = output.query('cuisine == \"test\"')\n",
    "    \n",
    "    train.cuisine.to_csv('data/cuisine.csv', header=False, encoding='utf-8')\n",
    "    \n",
    "    train = train.drop(columns=['cuisine'])\n",
    "    test = test.drop(columns=['cuisine'])\n",
    "    \n",
    "    train.to_csv('data/' + prefix + 'train.csv', header=True, encoding='utf-8') \n",
    "    test.to_csv('data/' + prefix + 'test.csv', header=True, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
